{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3833ac8-ae70-4374-bcaf-03d284c2492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from zipfile import ZipFile\n",
    "from zipfile import is_zipfile\n",
    "import io\n",
    "\n",
    "def zipextract(bucketname, zipfilename_with_path):\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucketname)\n",
    "\n",
    "    destination_blob_pathname = zipfilename_with_path\n",
    "        \n",
    "    blob = bucket.blob(destination_blob_pathname)\n",
    "    zipbytes = io.BytesIO(blob.download_as_string())\n",
    "\n",
    "    if is_zipfile(zipbytes):\n",
    "        with ZipFile(zipbytes, 'r') as myzip:\n",
    "            for contentfilename in myzip.namelist():\n",
    "                contentfile = myzip.read(contentfilename)\n",
    "                blob = bucket.blob(zipfilename_with_path + \"/\" + contentfilename)\n",
    "                blob.upload_from_string(contentfile)\n",
    "\n",
    "#zipextract(\"different-images\", \"archive.zip\") # if the file is gs://different-images/archive.zip\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4c992e37-5f51-4745-83a9-8810b8dbf910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "\n",
    "f = open(\"data_init.txt\", \"w\")\n",
    "f.write(\"path\" + \",\" + \"label\" + \"\\n\")\n",
    "\n",
    "data_store_in_list = []\n",
    "def file_location_and_Labelling(bucket_name, prefixname):\n",
    "    bucketname = bucket_name #'different-images'\n",
    "    client = storage.Client()\n",
    "\n",
    "    #for blob in client.list_blobs(bucketname, prefix='archive.zip'):\n",
    "    #  print(str(blob))\n",
    "    allFiles=[]\n",
    "    for blob in client.list_blobs(bucketname, prefix=prefixname): #'archive.zip/seg_train/seg_train'):\n",
    "      #print(blob.name)\n",
    "        allFiles.append(blob.name)\n",
    "\n",
    "    #print(len(allFiles))\n",
    "    for pathFile in allFiles:   \n",
    "        if pathFile.split(\"/\")[3] in ('buildings', 'forest', 'mountain', 'sea'):\n",
    "            #print(pathFile, pathFile.split(\"/\")[3])\n",
    "            f.write(\"gs://different-images/\"+pathFile + \",\" + pathFile.split(\"/\")[3])\n",
    "            f.write(\"\\n\")\n",
    "            \n",
    "            #data_store_in_list.append(pathFile pathFile.split(\"/\")[3])\n",
    "    \n",
    "## Output --> archive.zip/seg_train/seg_train/buildings/0.jpg buildings\n",
    "Bucket = 'different-images'\n",
    "Prefix1 = 'archive.zip/seg_train/seg_train'\n",
    "file_location_and_Labelling(Bucket, Prefix1)\n",
    "#print(len(data_store_in_list))\n",
    "f.close()\n",
    "\n",
    "\n",
    "read_file = pd.read_csv ('data_init.txt')\n",
    "read_file.to_csv ('train_data.csv', index=False, header= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3cadc9a-19d0-4c2b-af68-a5a47c6bd20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://train_data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][708.8 KiB/708.8 KiB]                                                \n",
      "Operation completed over 1 objects/708.8 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp train_data.csv gs://different-images/archive.zip/seg_train/seg_train/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e4cf69e-bbc6-4414-94f7-91c0ed1f2ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.7/site-packages (from opencv-python) (1.21.6)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55990069-156a-4749-93e9-ce48277dbb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 39.0M  100 39.0M    0     0  29.3M      0  0:00:01  0:00:01 --:--:-- 29.3M\n",
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:./ffmpeg-5.1.1-amd64-static\n",
      "\n",
      "./ffmpeg-5.1.1-amd64-static/ffmpeg\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "exist = !which ffmpeg\n",
    "if not exist:\n",
    "  !curl https://johnvansickle.com/ffmpeg/releases/ffmpeg-release-amd64-static.tar.xz -o ffmpeg.tar.xz \\\n",
    "     && tar -xf ffmpeg.tar.xz && rm ffmpeg.tar.xz\n",
    "  ffmdir = !find . -iname ffmpeg-*-static\n",
    "  path = %env PATH\n",
    "  path = path + ':' + ffmdir[0]\n",
    "  %env PATH $path\n",
    "print('')\n",
    "!which ffmpeg\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ade3b677-421d-4977-913d-2e009568689e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/jupyter/gcp-demo/10secVideo.ogv.\n",
      "MoviePy - Writing audio in 10secVideoTEMP_MPY_wvf_snd.ogg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/jupyter/gcp-demo/10secVideo.ogv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jupyter/gcp-demo/10secVideo.ogv\n"
     ]
    }
   ],
   "source": [
    "# !pip install pydub\n",
    "\n",
    "# !pip install av\n",
    "\n",
    "#apt-get install ffmpeg\n",
    "\n",
    "#brew install ffmpeg\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import random\n",
    "\n",
    "from moviepy.editor import AudioFileClip, ImageClip\n",
    "\n",
    "\n",
    "def get_random_10sec_audio_clip(srcAudioClip, destAudioClip):\n",
    "    sound = AudioSegment.from_mp3(srcAudioClip)\n",
    "\n",
    "    music_len = int(len(sound)) -20000\n",
    "    irand = random.randint(0, music_len)\n",
    "    \n",
    "    # Concatenation is just adding\n",
    "    music = sound[irand:irand+10000]\n",
    "\n",
    "    # writing mp3 files is a one liner\n",
    "    music.export(destAudioClip, format=\"mp3\")\n",
    "\n",
    "\n",
    "def add_static_image_to_audio(musicSrc, imageSrc, videoSrc):\n",
    "    \n",
    "    audio_clip = AudioFileClip(musicSrc)\n",
    "    image_clip = ImageClip(imageSrc)\n",
    "    #image_clip = ImageClip(\"/home/jupyter/gcp-demo/55.png\")\n",
    "    \n",
    "    video_clip = image_clip.set_audio(audio_clip)\n",
    "    # specify the duration of the new clip to be the duration of the audio clip\n",
    "    video_clip.duration = 10\n",
    "    # set the FPS to 1\n",
    "    video_clip.fps = 1\n",
    "    # write the resuling video clip\n",
    "    video_clip.write_videofile(videoSrc)\n",
    "\n",
    "\n",
    "music_src = \"/home/jupyter/gcp-demo/MountainMusic.mp3\"\n",
    "music_dest = \"/home/jupyter/gcp-demo/10secMusic.mp3\"\n",
    "\n",
    "get_random_10sec_audio_clip(music_src, music_dest)\n",
    "\n",
    "singleImageSrc = \"/home/jupyter/gcp-demo/42.jpg\"\n",
    "videoSrc = \"/home/jupyter/gcp-demo/10secVideo.ogv\"\n",
    "\n",
    "add_static_image_to_audio(music_dest, singleImageSrc, videoSrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12538732-e985-461b-bd90-da78a15582f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff9188bc-4159-443a-9f2f-1cd9e4bb9642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      " deployed_model_id: 2886864535749132288\n",
      " prediction: {'ids': ['2776353171797180416'], 'confidences': [0.858314157], 'displayNames': ['mountain']}\n",
      " prediction: {'ids': ['2776353171797180416'], 'confidences': [0.858314157], 'displayNames': ['mountain']}\n",
      "<proto.marshal.collections.maps.MapComposite object at 0x7fc83655a510>\n",
      "['mountain']\n",
      "mountain\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "\n",
    "\n",
    "def predict_image_classification_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    filename: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    with open(filename, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
    "    encoded_content = base64.b64encode(file_content).decode(\"utf-8\")\n",
    "    instance = predict.instance.ImageClassificationPredictionInstance(\n",
    "        content=encoded_content,\n",
    "    ).to_value()\n",
    "    instances = [instance]\n",
    "    # See gs://google-cloud-aiplatform/schema/predict/params/image_classification_1.0.0.yaml for the format of the parameters.\n",
    "    parameters = predict.params.ImageClassificationPredictionParams(\n",
    "        confidence_threshold=0.5, max_predictions=5,\n",
    "    ).to_value()\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    print(\"response\")\n",
    "    print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    # See gs://google-cloud-aiplatform/schema/predict/prediction/image_classification_1.0.0.yaml for the format of the predictions.\n",
    "    predictions = response.predictions\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", dict(prediction))\n",
    "        \n",
    "    return predictions\n",
    "        \n",
    "predictions_in_main_function = predict_image_classification_sample(\n",
    "    project=\"643948302050\",\n",
    "    endpoint_id=\"8669152205758005248\",\n",
    "    location=\"us-central1\",\n",
    "    filename=\"/home/jupyter/gcp-demo/42.jpg\"\n",
    ")\n",
    "\n",
    "for prediction in predictions_in_main_function:\n",
    "    print(\" prediction:\", dict(prediction))\n",
    "\n",
    "print(prediction)\n",
    "print(prediction['displayNames'])\n",
    "print(prediction['displayNames'][0])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daf5f308-a052-45a3-ad08-3346dbd61679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response\n",
      " deployed_model_id: 2886864535749132288\n",
      " prediction: {'confidences': [0.977521181], 'displayNames': ['sea'], 'ids': ['1623431667190333440']}\n",
      " prediction: {'confidences': [0.977521181], 'displayNames': ['sea'], 'ids': ['1623431667190333440']}\n",
      "sea\n",
      "/home/jupyter/gcp-demo/SeaMusic.mp3\n",
      "/home/jupyter/gcp-demo/10secMusic.mp3\n",
      "/home/jupyter/gcp-demo/10secVideo-sea2022Oct08.ogv\n",
      "Moviepy - Building video /home/jupyter/gcp-demo/10secVideo-sea2022Oct08.ogv.\n",
      "MoviePy - Writing audio in 10secVideo-sea2022Oct08TEMP_MPY_wvf_snd.ogg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video /home/jupyter/gcp-demo/10secVideo-sea2022Oct08.ogv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jupyter/gcp-demo/10secVideo-sea2022Oct08.ogv\n",
      "--------------------------------------\n",
      "-------------File Created-------------\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "import random\n",
    "\n",
    "from moviepy.editor import AudioFileClip, ImageClip\n",
    "\n",
    "import base64\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "def predict_image_classification_sample(\n",
    "    project: str,\n",
    "    endpoint_id: str,\n",
    "    filename: str,\n",
    "    location: str = \"us-central1\",\n",
    "    api_endpoint: str = \"us-central1-aiplatform.googleapis.com\",\n",
    "):\n",
    "    # The AI Platform services require regional API endpoints.\n",
    "    client_options = {\"api_endpoint\": api_endpoint}\n",
    "    # Initialize client that will be used to create and send requests.\n",
    "    # This client only needs to be created once, and can be reused for multiple requests.\n",
    "    client = aiplatform.gapic.PredictionServiceClient(client_options=client_options)\n",
    "    with open(filename, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    # The format of each instance should conform to the deployed model's prediction input schema.\n",
    "    encoded_content = base64.b64encode(file_content).decode(\"utf-8\")\n",
    "    instance = predict.instance.ImageClassificationPredictionInstance(\n",
    "        content=encoded_content,\n",
    "    ).to_value()\n",
    "    instances = [instance]\n",
    "    # See gs://google-cloud-aiplatform/schema/predict/params/image_classification_1.0.0.yaml for the format of the parameters.\n",
    "    parameters = predict.params.ImageClassificationPredictionParams(\n",
    "        confidence_threshold=0.5, max_predictions=5,\n",
    "    ).to_value()\n",
    "    endpoint = client.endpoint_path(\n",
    "        project=project, location=location, endpoint=endpoint_id\n",
    "    )\n",
    "    response = client.predict(\n",
    "        endpoint=endpoint, instances=instances, parameters=parameters\n",
    "    )\n",
    "    #print(\"response\")\n",
    "    #print(\" deployed_model_id:\", response.deployed_model_id)\n",
    "    # See gs://google-cloud-aiplatform/schema/predict/prediction/image_classification_1.0.0.yaml for the format of the predictions.\n",
    "    predictions = response.predictions\n",
    "    for prediction in predictions:\n",
    "        print(\" prediction:\", dict(prediction))\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def get_random_10sec_audio_clip(srcAudioClip, destAudioClip):\n",
    "    sound = AudioSegment.from_mp3(srcAudioClip)\n",
    "\n",
    "    music_len = int(len(sound)) -20000\n",
    "    irand = random.randint(0, music_len)\n",
    "    \n",
    "    # Concatenation is just adding\n",
    "    music = sound[irand:irand+10000]\n",
    "\n",
    "    # writing mp3 files is a one liner\n",
    "    music.export(destAudioClip, format=\"mp3\")\n",
    "\n",
    "\n",
    "def add_static_image_to_audio(musicSrc, imageSrc, videoSrc):\n",
    "    \n",
    "    audio_clip = AudioFileClip(musicSrc)\n",
    "    image_clip = ImageClip(imageSrc)\n",
    "    #image_clip = ImageClip(\"/home/jupyter/gcp-demo/55.png\")\n",
    "    \n",
    "    video_clip = image_clip.set_audio(audio_clip)\n",
    "    # specify the duration of the new clip to be the duration of the audio clip\n",
    "    video_clip.duration = 10\n",
    "    # set the FPS to 1\n",
    "    video_clip.fps = 1\n",
    "    # write the resuling video clip\n",
    "    video_clip.write_videofile(videoSrc)\n",
    "    \n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"-------------File Created-------------\")\n",
    "    print(\"--------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################\n",
    "\n",
    "#######  Here is the Uput ##########\n",
    "singleImageSrc=\"/home/jupyter/gcp-demo/AS-sea.jpeg\"\n",
    "\n",
    "####################################\n",
    "\n",
    "\n",
    "predictions_in_main_function = predict_image_classification_sample(\n",
    "    project=\"PROJECT_ID\",\n",
    "    endpoint_id=\"ENDPOINT_ID\",\n",
    "    location=\"us-central1\",\n",
    "    filename = singleImageSrc\n",
    ")\n",
    "\n",
    "for prediction_main in predictions_in_main_function:\n",
    "    print(\" prediction:\", dict(prediction_main))\n",
    "\n",
    "#print(prediction_main['displayNames'][0])\n",
    "\n",
    "music_src = \"\"\n",
    "music_dest = \"\"\n",
    "videoSrc = \"\"\n",
    "\n",
    "if prediction['displayNames'][0] == \"mountain\":\n",
    "    music_src = \"/home/jupyter/gcp-demo/MountainMusic.mp3\"\n",
    "    music_dest = \"/home/jupyter/gcp-demo/10secMusic.mp3\"       \n",
    "    videoSrc = \"/home/jupyter/gcp-demo/10secVideo-%s%s.ogv\" %(prediction_main['displayNames'][0], date.today().strftime(\"%Y%b%d\"))\n",
    "\n",
    "elif prediction['displayNames'][0] == \"sea\":\n",
    "    music_src = \"/home/jupyter/gcp-demo/SeaMusic.mp3\"\n",
    "    music_dest = \"/home/jupyter/gcp-demo/10secMusic.mp3\"       \n",
    "    videoSrc = \"/home/jupyter/gcp-demo/10secVideo-%s%s.ogv\" %(prediction_main['displayNames'][0], date.today().strftime(\"%Y%b%d\"))\n",
    "    \n",
    "\n",
    "get_random_10sec_audio_clip(music_src, music_dest)\n",
    "add_static_image_to_audio(music_dest, singleImageSrc, videoSrc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef805e-8f66-4b01-a218-b6e0e86b9eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
